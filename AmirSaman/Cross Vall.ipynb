{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_name_list = glob.glob(\"*.csv\")\n",
    "\n",
    "feature_set = ['DEPTH','CALI', 'DENB', 'DRHO', 'GR','RDEEP','NEUT', 'RMICRO', 'DTCOMP']\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in file_name_list:\n",
    "    df = pd.read_csv(file, index_col=None, skiprows=[1])\n",
    "    file_list.append(df[feature_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plt_this(y):\n",
    "    plt.plot(y)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_res(dept, pred_y, err, well, algo_name):\n",
    "    res_path = \"Results/%s\"  %well\n",
    "    if not os.path.isdir(res_path):\n",
    "        os.makedirs(res_path)\n",
    "        \n",
    "    result = pd.DataFrame({'NEUT': dept,\n",
    "                           'Pred_NEUT': pred_y})\n",
    "    result.to_csv('%s/%s.csv' %(res_path, algo_name))\n",
    "    \n",
    "    score = pd.DataFrame({'ERROR' : [err]})\n",
    "    score.to_csv('%s/%s_score.csv' %(res_path, algo_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "\n",
    "def cross_val(clf, algo_name, feature_set=['DEPTH','CALI', 'DENB', 'DRHO', 'GR', 'RDEEP', 'RMICRO', 'DTCOMP']):\n",
    "    \n",
    "    wells = []\n",
    "    err_list = []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        test_df = file_list[i]\n",
    "        wells.append(test_df.iloc[0,0])\n",
    "        print('%s : %s' %(i, wells[i]))\n",
    "\n",
    "        train_list = file_list.copy()\n",
    "        train_list.pop(i)\n",
    "        train_df = pd.concat(train_list)\n",
    "\n",
    "        test_x = test_df[feature_set].values\n",
    "        test_y = test_df[['NEUT']].values\n",
    "        test_y = test_y.ravel()\n",
    "        \n",
    "        train_X = train_df[feature_set].values\n",
    "        train_y = train_df[['NEUT']].values\n",
    "        train_y = train_y.ravel()\n",
    "        \n",
    "        # feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit_transform(train_X)\n",
    "        scaler.transform(test_x)\n",
    "\n",
    "        # training\n",
    "        mdl = clf()\n",
    "        mdl.fit(train_X, train_y)\n",
    "        \n",
    "        # testing\n",
    "        pred_y = mdl.predict(test_x)\n",
    "    \n",
    "        # error\n",
    "#         abs_error = np.divide((np.abs(np.subtract(test_y, pred_y))), test_y)\n",
    "        \n",
    "#         plt_this(abs_error)\n",
    "#         plt_this(pred_y)\n",
    "#         plt_this(test_y)\n",
    "            \n",
    "#         err = explained_variance_score(test_y, pred_y)\n",
    "        err = r2_score(test_y, pred_y)\n",
    "        \n",
    "        err_list.append(err)\n",
    "        \n",
    "        # save results\n",
    "        save_res(test_x[:,0], pred_y, err, wells[i], algo_name)\n",
    "\n",
    "    print()\n",
    "\n",
    "    avg_err = np.mean(err_list)\n",
    "\n",
    "    for i in range(len(wells)):\n",
    "        print('Test score on %s : %s' %(wells[i], err_list[i]))\n",
    "\n",
    "    print()\n",
    "    print('Average algorithm score: %s' %avg_err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 316.3824\n",
      "1 : 335.4324\n",
      "2 : 318.2112\n",
      "3 : 268.3764\n",
      "4 : 305.562\n",
      "5 : 328.8792\n",
      "\n",
      "Test score on 316.3824 : 0.996110547376185\n",
      "Test score on 335.4324 : 0.9774568062439419\n",
      "Test score on 318.2112 : 0.9834480676131058\n",
      "Test score on 268.3764 : 0.7514095143061121\n",
      "Test score on 305.562 : 0.999584912983053\n",
      "Test score on 328.8792 : 0.5978585225272584\n",
      "\n",
      "Average algorithm score: 0.8843113951749427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "feature_set = ['DEPTH', 'CALI', 'DENB', 'RDEEP', 'RMICRO'] #0.372\n",
    "\n",
    "cross_val(LinearRegression, 'Linear regression', feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 316.3824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 335.4324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : 318.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : 268.3764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : 305.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 328.8792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score on 316.3824 : 0.9993193267726772\n",
      "Test score on 335.4324 : 0.9774198155900885\n",
      "Test score on 318.2112 : 0.9869160262317125\n",
      "Test score on 268.3764 : 0.7497278443631334\n",
      "Test score on 305.562 : 0.977025448102083\n",
      "Test score on 328.8792 : 0.6596773325413249\n",
      "\n",
      "Average algorithm score: 0.8916809656001697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cross_val(RandomForestRegressor, 'Random forrest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 316.3824\n",
      "1 : 335.4324\n",
      "2 : 318.2112\n",
      "3 : 268.3764\n",
      "4 : 305.562\n",
      "5 : 328.8792\n",
      "\n",
      "Test score on 316.3824 : 0.9979816351949283\n",
      "Test score on 335.4324 : 0.9773096636945793\n",
      "Test score on 318.2112 : 0.9885475227345948\n",
      "Test score on 268.3764 : 0.7283395564012842\n",
      "Test score on 305.562 : 0.9855857509113958\n",
      "Test score on 328.8792 : -4.811721893305022\n",
      "\n",
      "Average algorithm score: -0.022326294061373247\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "cross_val(LGBMRegressor, 'Gradient boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 316.3824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 335.4324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : 318.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : 268.3764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "cross_val(SVR, 'Support vector machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cross_val(clf, algo_name, feature_set=['DEPTH','CALI', 'DENB', 'DRHO', 'GR','RDEEP', 'RMICRO', 'DTCOMP']):\n",
    "    \n",
    "    wells = []\n",
    "    err_list = []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        test_df = file_list[i]\n",
    "        wells.append(test_df.iloc[0,0])\n",
    "        print('%s : %s' %(i, wells[i]))\n",
    "\n",
    "        train_list = file_list.copy()\n",
    "        train_list.pop(i)\n",
    "        train_df = pd.concat(train_list)\n",
    "\n",
    "        test_x = test_df[feature_set].values\n",
    "        test_y = test_df[['NEUT']].values\n",
    "        test_y = test_y.ravel()\n",
    "        \n",
    "        train_X = train_df[feature_set].values\n",
    "        train_y = train_df[['NEUT']].values\n",
    "        train_y = train_y.ravel()\n",
    "        \n",
    "        # feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit_transform(train_X)\n",
    "        scaler.transform(test_x)\n",
    "\n",
    "        # training\n",
    "        mdl = clf()\n",
    "        mdl.fit(train_X, train_y)\n",
    "        \n",
    "        plot_tree(mdl, rankdir='LR')\n",
    "        plt.show()\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(150, 100)\n",
    "#         fig.savefig('tree.png')\n",
    "        fig.show()\n",
    "\n",
    "        # testing\n",
    "        pred_y = mdl.predict(test_x)\n",
    "    \n",
    "        # error\n",
    "#         abs_error = np.divide((np.abs(np.subtract(test_y, pred_y))), test_y)\n",
    "        \n",
    "#         plt_this(abs_error)\n",
    "#         plt_this(pred_y)\n",
    "#         plt_this(test_y)\n",
    "            \n",
    "#         err = explained_variance_score(test_y, pred_y)\n",
    "        err = r2_score(test_y, pred_y)\n",
    "        \n",
    "        err_list.append(err)\n",
    "        \n",
    "        # save results\n",
    "        save_res(test_x[:,0], pred_y, err, wells[i], algo_name)\n",
    "\n",
    "    print()\n",
    "\n",
    "    avg_err = np.mean(err_list)\n",
    "\n",
    "    for i in range(len(wells)):\n",
    "        print('Test score on %s : %s' %(wells[i], err_list[i]))\n",
    "\n",
    "    print()\n",
    "    print('Average algorithm score: %s' %avg_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "cross_val(XGBRegressor, 'xgbr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
