{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name_list = glob.glob(\"../../AmirSaman/Final/clean/*.csv\")\n",
    "\n",
    "feature_set = ['wellName','DEPTH', 'CALI', 'DENB', 'DRHO','DTCOMP', 'GR', 'NEUT','RDEEP', 'RMICRO']\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in file_name_list:\n",
    "    df = pd.read_csv(file, index_col=None, skiprows=[1])\n",
    "    file_list.append(df[feature_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plt_this(y):\n",
    "    plt.plot(y)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_res(dept, pred_y, err, well, algo_name):\n",
    "    res_path = \"Results/%s\"  %well\n",
    "    if not os.path.isdir(res_path):\n",
    "        os.makedirs(res_path)\n",
    "        \n",
    "    result = pd.DataFrame({'NEUT': dept,\n",
    "                           'Pred_NEUT': pred_y})\n",
    "    result.to_csv('%s/%s.csv' %(res_path, algo_name))\n",
    "    \n",
    "    score = pd.DataFrame({'ERROR' : [err]})\n",
    "    score.to_csv('%s/%s_score.csv' %(res_path, algo_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "\n",
    "def cross_val(clf, algo_name, feature_set=['DEPTH', 'CALI', 'DENB', 'DRHO','DTCOMP', 'GR', 'RDEEP', 'RMICRO']):\n",
    "    \n",
    "    wells = []\n",
    "    err_list = []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        test_df = file_list[i]\n",
    "        wells.append(test_df.iloc[0,0])\n",
    "        print('%s : %s' %(i, wells[i]))\n",
    "\n",
    "        train_list = file_list.copy()\n",
    "        train_list.pop(i)\n",
    "        train_df = pd.concat(train_list)\n",
    "\n",
    "        test_x = test_df[feature_set].values\n",
    "        test_y = test_df[['NEUT']].values\n",
    "        test_y = test_y.ravel()\n",
    "        \n",
    "        train_X = train_df[feature_set].values\n",
    "        train_y = train_df[['NEUT']].values\n",
    "        train_y = train_y.ravel()\n",
    "        \n",
    "        # feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit_transform(train_X)\n",
    "        scaler.transform(test_x)\n",
    "\n",
    "        # training\n",
    "        mdl = clf()\n",
    "        mdl.fit(train_X, train_y)\n",
    "        \n",
    "        # testing\n",
    "        pred_y = mdl.predict(test_x)\n",
    "    \n",
    "        # error\n",
    "#         abs_error = np.divide((np.abs(np.subtract(test_y, pred_y))), test_y)\n",
    "        \n",
    "#         plt_this(abs_error)\n",
    "#         plt_this(pred_y)\n",
    "#         plt_this(test_y)\n",
    "            \n",
    "#         err = explained_variance_score(test_y, pred_y)\n",
    "        err = r2_score(test_y, pred_y)\n",
    "        \n",
    "        err_list.append(err)\n",
    "        \n",
    "        # save results\n",
    "        save_res(test_x[:,0], pred_y, err, wells[i], algo_name)\n",
    "\n",
    "    print()\n",
    "\n",
    "    avg_err = np.mean(err_list)\n",
    "\n",
    "    for i in range(len(wells)):\n",
    "        print('Test score on %s : %s' %(wells[i], err_list[i]))\n",
    "\n",
    "    print()\n",
    "    print('Average algorithm score: %s' %avg_err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : WELL1COMPOSITE\n",
      "1 : WELL4COMPOSITE\n",
      "2 : WELL2COMPOSITE\n",
      "3 : WELL5COMPOSITE\n",
      "4 : WELL3COMPOSITE\n",
      "5 : WELL6COMPOSITE\n",
      "\n",
      "Test score on WELL1COMPOSITE : 0.9766166210510479\n",
      "Test score on WELL4COMPOSITE : 0.9763924881993657\n",
      "Test score on WELL2COMPOSITE : 0.9815734897638569\n",
      "Test score on WELL5COMPOSITE : 0.751518802177578\n",
      "Test score on WELL3COMPOSITE : 0.9981288565504328\n",
      "Test score on WELL6COMPOSITE : 0.5679568772634083\n",
      "\n",
      "Average algorithm score: 0.8753645225009482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "feature_set = ['DEPTH', 'CALI', 'DENB', 'DRHO','DTCOMP', 'GR', 'RDEEP', 'RMICRO'] #0.372\n",
    "\n",
    "cross_val(LinearRegression, 'Linear regression', feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : WELL1COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : WELL4COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : WELL2COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : WELL5COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : WELL3COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : WELL6COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score on WELL1COMPOSITE : 0.9993230191300995\n",
      "Test score on WELL4COMPOSITE : 0.9774310937625653\n",
      "Test score on WELL2COMPOSITE : 0.9873152577456992\n",
      "Test score on WELL5COMPOSITE : 0.7513376130004867\n",
      "Test score on WELL3COMPOSITE : 0.9754457676031499\n",
      "Test score on WELL6COMPOSITE : 0.5762196013756198\n",
      "\n",
      "Average algorithm score: 0.8778453921029367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cross_val(RandomForestRegressor, 'Random forrest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : WELL1COMPOSITE\n",
      "1 : WELL4COMPOSITE\n",
      "2 : WELL2COMPOSITE\n",
      "3 : WELL5COMPOSITE\n",
      "4 : WELL3COMPOSITE\n",
      "5 : WELL6COMPOSITE\n",
      "\n",
      "Test score on WELL1COMPOSITE : 0.9970597519181443\n",
      "Test score on WELL4COMPOSITE : 0.977328328985528\n",
      "Test score on WELL2COMPOSITE : 0.9882689998590557\n",
      "Test score on WELL5COMPOSITE : 0.7325851773176175\n",
      "Test score on WELL3COMPOSITE : 0.9854178754216131\n",
      "Test score on WELL6COMPOSITE : -4.911524287061389\n",
      "\n",
      "Average algorithm score: -0.03847735892657159\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "cross_val(LGBMRegressor, 'Gradient boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : WELL1COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : WELL4COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : WELL2COMPOSITE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : WELL5COMPOSITE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "cross_val(SVR, 'Support vector machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cross_val(clf, algo_name, feature_set=['DEPTH', 'CALI', 'DENB', 'DRHO','DTCOMP', 'GR', 'RDEEP', 'RMICRO']):\n",
    "    \n",
    "    wells = []\n",
    "    err_list = []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        test_df = file_list[i]\n",
    "        wells.append(test_df.iloc[0,0])\n",
    "        print('%s : %s' %(i, wells[i]))\n",
    "\n",
    "        train_list = file_list.copy()\n",
    "        train_list.pop(i)\n",
    "        train_df = pd.concat(train_list)\n",
    "\n",
    "        test_x = test_df[feature_set].values\n",
    "        test_y = test_df[['NEUT']].values\n",
    "        test_y = test_y.ravel()\n",
    "        \n",
    "        train_X = train_df[feature_set].values\n",
    "        train_y = train_df[['NEUT']].values\n",
    "        train_y = train_y.ravel()\n",
    "        \n",
    "        # feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit_transform(train_X)\n",
    "        scaler.transform(test_x)\n",
    "\n",
    "        # training\n",
    "        mdl = clf()\n",
    "        mdl.fit(train_X, train_y)\n",
    "        \n",
    "        plot_tree(mdl, rankdir='LR')\n",
    "#         plt.show()\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(150, 100)\n",
    "#         fig.savefig('tree.png')\n",
    "        fig.show()\n",
    "\n",
    "        # testing\n",
    "        pred_y = mdl.predict(test_x)\n",
    "    \n",
    "        # error\n",
    "#         abs_error = np.divide((np.abs(np.subtract(test_y, pred_y))), test_y)\n",
    "        \n",
    "#         plt_this(abs_error)\n",
    "#         plt_this(pred_y)\n",
    "#         plt_this(test_y)\n",
    "            \n",
    "#         err = explained_variance_score(test_y, pred_y)\n",
    "        err = r2_score(test_y, pred_y)\n",
    "        \n",
    "        err_list.append(err)\n",
    "        \n",
    "        # save results\n",
    "        save_res(test_x[:,0], pred_y, err, wells[i], algo_name)\n",
    "\n",
    "    print()\n",
    "\n",
    "    avg_err = np.mean(err_list)\n",
    "\n",
    "    for i in range(len(wells)):\n",
    "        print('Test score on %s : %s' %(wells[i], err_list[i]))\n",
    "\n",
    "    print()\n",
    "    print('Average algorithm score: %s' %avg_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "cross_val(XGBRegressor, 'xgbr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
